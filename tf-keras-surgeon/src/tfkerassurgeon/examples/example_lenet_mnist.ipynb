{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "example_lenet_mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dan1HjbGDaWo",
        "colab_type": "code",
        "outputId": "af400e3d-c96e-4284-eafe-d58ad87e2720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        }
      },
      "source": [
        "! pip uninstall -y tensorflow\n",
        "! pip uninstall -y tf-nightly\n",
        "\n",
        "! pip install tensorflow-gpu==2.0.0-beta1\n",
        "\n",
        "! pip install tfkerassurgeon\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Skipping tf-nightly as it is not installed.\u001b[0m\n",
            "Uninstalling tensorflow-gpu-2.0.0b1:\n",
            "  Successfully uninstalled tensorflow-gpu-2.0.0b1\n",
            "Uninstalling tfkerassurgeon-0.2.1:\n",
            "  Successfully uninstalled tfkerassurgeon-0.2.1\n",
            "Collecting tensorflow-gpu==2.0.0-beta1\n",
            "  Using cached https://files.pythonhosted.org/packages/2b/53/e18c5e7a2263d3581a979645a185804782e59b8e13f42b9c3c3cfb5bb503/tensorflow_gpu-2.0.0b1-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.11.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.1.7)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.33.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.12.0)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.14.0.dev2019060501)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.2.2)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.14.0a20190603)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (3.7.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.8.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.16.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-beta1) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (0.15.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (41.0.1)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.0.0b1\n",
            "Collecting tfkerassurgeon\n",
            "Installing collected packages: tfkerassurgeon\n",
            "Successfully installed tfkerassurgeon-0.2.1\n",
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Skipping tf-nightly as it is not installed.\u001b[0m\n",
            "Requirement already satisfied: tensorflow-gpu==2.0.0-beta1 in /usr/local/lib/python3.6/dist-packages (2.0.0b1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.1.7)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.8.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (3.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.33.4)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.14.0a20190603)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.11.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.16.4)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.14.0.dev2019060501)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-beta1) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-beta1) (41.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (3.1.1)\n",
            "Requirement already satisfied: tfkerassurgeon in /usr/local/lib/python3.6/dist-packages (0.2.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d-JgZUzUWpP",
        "colab_type": "code",
        "outputId": "d075ea4c-6901-4797-c470-16868b475200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras import activations\n",
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras import backend\n",
        "from tensorflow.python.keras import callbacks\n",
        "from tensorflow.python.keras.datasets import mnist\n",
        "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
        "\n",
        "import tfkerassurgeon\n",
        "from tfkerassurgeon import identify\n",
        "from tfkerassurgeon.operations import delete_channels\n",
        "\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-beta1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfwJo-gYz2-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Set some static values that can be tweaked to experiment\n",
        "keras_verbosity = 2 # limits the printed output but still gets the Epoch stats\n",
        "epochs=200 # we'd never reach 200 because we have early stopping\n",
        "batch_size=128 # tweak this depending on your hardware and Model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rM72tZez3B5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Load the dataset (it will automatically download it if needed), they provided a nice helper that does all the network and downloading for you\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "# This is an leterantive to the MNIST numbers dataset that is a computationlally harder problem\n",
        "#(X_train, Y_train), (X_test, Y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# we need to make sure that the images are normalized and in the right format\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# expand the dimensions to get the shape to (samples, height, width, channels) where greyscale has 1 channel\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "X_test = np.expand_dims(X_test, axis=-1)\n",
        "\n",
        "# one-hot encoding, this way, each digit has a probability output\n",
        "Y_train = to_categorical(Y_train, 10)\n",
        "Y_test = to_categorical(Y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku8uWZ4az3Gf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Simple reusable shorthand to compile the model, so that we can be sure to use the same optomizer, loss, and metrics\n",
        "def compile_model(model):\n",
        "    \n",
        "    model.compile(optimizer='adam',\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1_m2nNez26i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# method that encapsulates the Models archeteture and construction\n",
        "def build_model():\n",
        "\n",
        "    # Create LeNet model\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(20,\n",
        "                     [3, 3],\n",
        "                     input_shape=[28, 28, 1],\n",
        "                     activation='relu',\n",
        "                     name='conv_1'))\n",
        "    model.add(layers.MaxPool2D())\n",
        "    model.add(layers.Conv2D(50, [3, 3], activation='relu', name='conv_2'))\n",
        "    model.add(layers.MaxPool2D())\n",
        "    model.add(layers.Permute((2, 1, 3)))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(500, activation='relu', name='dense_1'))\n",
        "    model.add(layers.Dense(10, activation='softmax', name='dense_2'))\n",
        "\n",
        "    compile_model(model)\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EueuGY1z_ug",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5a25b589-64c4-4cf7-9c0f-388cae5dc0af"
      },
      "source": [
        "\n",
        "# a simple method that gets the callbacks for training\n",
        "def get_callbacks(use_early_stopping = True, use_reduce_lr = True):\n",
        "\n",
        "    callback_list = []\n",
        "\n",
        "    if(use_early_stopping):\n",
        "\n",
        "        callback_list.append(callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                             min_delta=0,\n",
        "                                             patience=10,\n",
        "                                             verbose=keras_verbosity,\n",
        "                                             mode='auto'))\n",
        "\n",
        "    if(use_reduce_lr):\n",
        "\n",
        "        callback_list.append(callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                                            factor=0.1,\n",
        "                                            patience=5,\n",
        "                                            verbose=keras_verbosity,\n",
        "                                            mode='auto',\n",
        "                                            epsilon=0.0001,\n",
        "                                            cooldown=0,\n",
        "                                            min_lr=0))\n",
        "\n",
        "    return callback_list\n",
        "\n",
        "# and get the callbacks\n",
        "callback_list = get_callbacks()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0802 02:05:03.868893 140189758031744 callbacks.py:1781] `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF7DbGaAz_xP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Simple reusable shorthand for evaluating the model on the Validation set \n",
        "def fit_model(model):\n",
        "    \n",
        "    return model.fit(\n",
        "                    X_train,\n",
        "                    Y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    verbose=keras_verbosity,\n",
        "                    validation_data=(X_test, Y_test),\n",
        "                    callbacks=callback_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98A1fJqcz_1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Simple reusable shorthand for evaluating the model on the Validation set \n",
        "def eval_model(model):\n",
        "\n",
        "    return model.evaluate(\n",
        "                        X_test, \n",
        "                        Y_test, \n",
        "                        batch_size=batch_size, \n",
        "                        verbose=keras_verbosity)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUKa3ANfz_8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# THIS IS WHERE THE MAGIC HAPPENS!\n",
        "# This method uses the Keras Surgeon to identify which parts od a layer can be pruned and then deletes them\n",
        "# Note: it returns the new, pruned model, that was recompiled\n",
        "def prune_layer(model, layer):\n",
        "    \n",
        "    # Get the APOZ (Average Percentage of Zeros) that should identify where we can prune\n",
        "    apoz = identify.get_apoz(model, layer, X_test)\n",
        "\n",
        "    # Get the Channel Ids that have a high APOZ, which indicates they can be pruned\n",
        "    high_apoz_channels = identify.high_apoz(apoz)\n",
        "\n",
        "    # Run the pruning on the Model and get the Pruned (uncompiled) model as a result\n",
        "    model = delete_channels(model, layer, high_apoz_channels)\n",
        "\n",
        "    # Recompile the model\n",
        "    compile_model(model)\n",
        "\n",
        "    return model\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWaCTapg0IlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# A helper that gets the layer by it's name \n",
        "def prune_layer_by_name(model, layer_name):\n",
        "\n",
        "    # First we get the layer we are working on\n",
        "    layer = model.get_layer(name=layer_name)\n",
        "    # Then prune is and return the pruned model\n",
        "    return prune_layer(model, layer)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-6fPJQt0In-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# the main function, that runs the training\n",
        "def main(): \n",
        "\n",
        "    \n",
        "    # build the model\n",
        "    model = build_model()\n",
        "\n",
        "    # Initial Train on dataset\n",
        "    results = fit_model(model)\n",
        "\n",
        "    # eval and print the results of the training\n",
        "    loss = eval_model(model)\n",
        "    print('original model loss:', loss, '\\n')\n",
        "    \n",
        "    # NOTE: This while true will continue until it ERRORs out because there is no escape condition.\n",
        "    while True:\n",
        "\n",
        "        # only prune the Dense layer for this example\n",
        "        layer_name = 'dense_1'\n",
        "        # Run the Pruning on the layer\n",
        "        model = prune_layer_by_name(model, layer_name)\n",
        "\n",
        "        # eval and print the results of the pruning\n",
        "        loss = eval_model(model)\n",
        "        print('model loss after pruning: ', loss, '\\n')\n",
        "        \n",
        "        # Retrain the model to accomodate for the changes\n",
        "        results = fit_model(model)\n",
        "\n",
        "        # eval and print the results of the retraining\n",
        "        loss = eval_model(model)\n",
        "        print('model loss after retraining: ', loss, '\\n')\n",
        "\n",
        "        # While TRUE will repeat until an ERROR occurs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjEpABn8DyLN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f7ea3ae9-db58-43d1-8edc-affd18d43ceb"
      },
      "source": [
        "\n",
        "# Run the main Method\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0802 02:05:04.909610 140189758031744 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 4s - loss: 0.1878 - accuracy: 0.9465 - val_loss: 0.0492 - val_accuracy: 0.9840\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 0.0499 - accuracy: 0.9847 - val_loss: 0.0335 - val_accuracy: 0.9890\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 0.0351 - accuracy: 0.9888 - val_loss: 0.0352 - val_accuracy: 0.9888\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 0.0259 - accuracy: 0.9917 - val_loss: 0.0302 - val_accuracy: 0.9906\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 0.0185 - accuracy: 0.9937 - val_loss: 0.0298 - val_accuracy: 0.9893\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0326 - val_accuracy: 0.9901\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.0388 - val_accuracy: 0.9890\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 0.0097 - accuracy: 0.9966 - val_loss: 0.0377 - val_accuracy: 0.9892\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.0328 - val_accuracy: 0.9903\n",
            "Epoch 10/200\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.0305 - val_accuracy: 0.9924\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0241 - val_accuracy: 0.9941\n",
            "Epoch 12/200\n",
            "60000/60000 - 2s - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0249 - val_accuracy: 0.9943\n",
            "Epoch 13/200\n",
            "60000/60000 - 2s - loss: 8.6674e-04 - accuracy: 0.9999 - val_loss: 0.0251 - val_accuracy: 0.9942\n",
            "Epoch 14/200\n",
            "60000/60000 - 2s - loss: 7.2041e-04 - accuracy: 0.9999 - val_loss: 0.0258 - val_accuracy: 0.9941\n",
            "Epoch 15/200\n",
            "60000/60000 - 2s - loss: 6.2750e-04 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9941\n",
            "Epoch 16/200\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 5.6256e-04 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9941\n",
            "Epoch 17/200\n",
            "60000/60000 - 2s - loss: 4.8987e-04 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9940\n",
            "Epoch 18/200\n",
            "60000/60000 - 2s - loss: 4.8234e-04 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 0.9940\n",
            "Epoch 19/200\n",
            "60000/60000 - 2s - loss: 4.7666e-04 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 0.9940\n",
            "Epoch 20/200\n",
            "60000/60000 - 2s - loss: 4.7045e-04 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 0.9940\n",
            "Epoch 21/200\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "60000/60000 - 2s - loss: 4.6258e-04 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9940\n",
            "Epoch 00021: early stopping\n",
            "10000/10000 - 0s - loss: 0.0270 - accuracy: 0.9940\n",
            "original model loss: [0.026955610954202847, 0.994] \n",
            "\n",
            "Deleting 114/500 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.0269 - accuracy: 0.9939\n",
            "model loss after pruning:  [0.026867122509008322, 0.9939] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0384 - val_accuracy: 0.9911\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0295 - val_accuracy: 0.9922\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.0382 - val_accuracy: 0.9897\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0334 - val_accuracy: 0.9921\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0404 - val_accuracy: 0.9919\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0348 - val_accuracy: 0.9918\n",
            "Epoch 7/200\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0327 - val_accuracy: 0.9932\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0293 - val_accuracy: 0.9936\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 5.8387e-04 - accuracy: 0.9999 - val_loss: 0.0304 - val_accuracy: 0.9935\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 4.4762e-04 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 0.9935\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 3.9602e-04 - accuracy: 1.0000 - val_loss: 0.0307 - val_accuracy: 0.9938\n",
            "Epoch 12/200\n",
            "60000/60000 - 2s - loss: 3.6862e-04 - accuracy: 1.0000 - val_loss: 0.0309 - val_accuracy: 0.9937\n",
            "Epoch 13/200\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 3.4669e-04 - accuracy: 1.0000 - val_loss: 0.0312 - val_accuracy: 0.9938\n",
            "Epoch 14/200\n",
            "60000/60000 - 2s - loss: 3.3213e-04 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.9938\n",
            "Epoch 15/200\n",
            "60000/60000 - 2s - loss: 3.3059e-04 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.9938\n",
            "Epoch 16/200\n",
            "60000/60000 - 2s - loss: 3.2881e-04 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 0.9938\n",
            "Epoch 17/200\n",
            "60000/60000 - 2s - loss: 3.2676e-04 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 0.9938\n",
            "Epoch 18/200\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "60000/60000 - 2s - loss: 3.2441e-04 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 0.9938\n",
            "Epoch 00018: early stopping\n",
            "10000/10000 - 0s - loss: 0.0315 - accuracy: 0.9938\n",
            "model loss after retraining:  [0.03150126729441784, 0.9938] \n",
            "\n",
            "Deleting 68/386 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.0325 - accuracy: 0.9928\n",
            "model loss after pruning:  [0.03248735009964803, 0.9928] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0335 - val_accuracy: 0.9923\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0425 - val_accuracy: 0.9920\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0403 - val_accuracy: 0.9901\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0449 - val_accuracy: 0.9912\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0405 - val_accuracy: 0.9924\n",
            "Epoch 6/200\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0460 - val_accuracy: 0.9910\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0364 - val_accuracy: 0.9930\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 4.2414e-04 - accuracy: 1.0000 - val_loss: 0.0352 - val_accuracy: 0.9932\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 3.6476e-04 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 0.9936\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 3.3849e-04 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 0.9936\n",
            "Epoch 11/200\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 3.2336e-04 - accuracy: 1.0000 - val_loss: 0.0351 - val_accuracy: 0.9937\n",
            "Epoch 00011: early stopping\n",
            "10000/10000 - 0s - loss: 0.0351 - accuracy: 0.9937\n",
            "model loss after retraining:  [0.03509261057506849, 0.9937] \n",
            "\n",
            "Deleting 39/318 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.0346 - accuracy: 0.9927\n",
            "model loss after pruning:  [0.03462565447765831, 0.9927] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0395 - val_accuracy: 0.9915\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0366 - val_accuracy: 0.9929\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0476 - val_accuracy: 0.9905\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0373 - val_accuracy: 0.9922\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0412 - val_accuracy: 0.9919\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0419 - val_accuracy: 0.9919\n",
            "Epoch 7/200\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0486 - val_accuracy: 0.9903\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0402 - val_accuracy: 0.9912\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 4.6101e-04 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9917\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 3.2998e-04 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9917\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 3.1177e-04 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9920\n",
            "Epoch 12/200\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 3.0188e-04 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9919\n",
            "Epoch 00012: early stopping\n",
            "10000/10000 - 0s - loss: 0.0390 - accuracy: 0.9919\n",
            "model loss after retraining:  [0.039029678286327044, 0.9919] \n",
            "\n",
            "Deleting 41/279 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.0394 - accuracy: 0.9917\n",
            "model loss after pruning:  [0.03942288415856697, 0.9917] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0424 - val_accuracy: 0.9911\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0407 - val_accuracy: 0.9907\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 8.0395e-04 - accuracy: 0.9998 - val_loss: 0.0495 - val_accuracy: 0.9900\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0420 - val_accuracy: 0.9918\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0416 - val_accuracy: 0.9917\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0544 - val_accuracy: 0.9922\n",
            "Epoch 7/200\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0497 - val_accuracy: 0.9907\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0383 - val_accuracy: 0.9933\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 4.0818e-04 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9931\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 3.3585e-04 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 0.9932\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 3.1787e-04 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 0.9930\n",
            "Epoch 12/200\n",
            "60000/60000 - 2s - loss: 3.0621e-04 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9931\n",
            "Epoch 13/200\n",
            "60000/60000 - 2s - loss: 2.9822e-04 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9933\n",
            "Epoch 14/200\n",
            "60000/60000 - 2s - loss: 2.9226e-04 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9932\n",
            "Epoch 15/200\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 2.8765e-04 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9932\n",
            "Epoch 16/200\n",
            "60000/60000 - 2s - loss: 2.8460e-04 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9932\n",
            "Epoch 17/200\n",
            "60000/60000 - 2s - loss: 2.8423e-04 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9932\n",
            "Epoch 18/200\n",
            "60000/60000 - 2s - loss: 2.8379e-04 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9932\n",
            "Epoch 19/200\n",
            "60000/60000 - 2s - loss: 2.8328e-04 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9932\n",
            "Epoch 20/200\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "60000/60000 - 2s - loss: 2.8269e-04 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9932\n",
            "Epoch 00020: early stopping\n",
            "10000/10000 - 0s - loss: 0.0382 - accuracy: 0.9932\n",
            "model loss after retraining:  [0.03823870615398323, 0.9932] \n",
            "\n",
            "Deleting 37/238 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.0400 - accuracy: 0.9924\n",
            "model loss after pruning:  [0.04004461831818781, 0.9924] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0502 - val_accuracy: 0.9918\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0487 - val_accuracy: 0.9917\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0514 - val_accuracy: 0.9911\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 4.8282e-04 - accuracy: 0.9999 - val_loss: 0.0495 - val_accuracy: 0.9915\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0462 - val_accuracy: 0.9919\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0502 - val_accuracy: 0.9912\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0451 - val_accuracy: 0.9916\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0498 - val_accuracy: 0.9919\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0489 - val_accuracy: 0.9912\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0552 - val_accuracy: 0.9907\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0512 - val_accuracy: 0.9906\n",
            "Epoch 12/200\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0451 - val_accuracy: 0.9923\n",
            "Epoch 13/200\n",
            "60000/60000 - 2s - loss: 3.1939e-04 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9922\n",
            "Epoch 14/200\n",
            "60000/60000 - 2s - loss: 2.9068e-04 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9920\n",
            "Epoch 15/200\n",
            "60000/60000 - 2s - loss: 2.8656e-04 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9922\n",
            "Epoch 16/200\n",
            "60000/60000 - 2s - loss: 2.8375e-04 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9922\n",
            "Epoch 17/200\n",
            "60000/60000 - 2s - loss: 2.8157e-04 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9923\n",
            "Epoch 18/200\n",
            "60000/60000 - 2s - loss: 2.7978e-04 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 0.9922\n",
            "Epoch 19/200\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 2.7824e-04 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9920\n",
            "Epoch 20/200\n",
            "60000/60000 - 2s - loss: 2.7712e-04 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9920\n",
            "Epoch 21/200\n",
            "60000/60000 - 2s - loss: 2.7697e-04 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9920\n",
            "Epoch 22/200\n",
            "60000/60000 - 2s - loss: 2.7680e-04 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9920\n",
            "Epoch 23/200\n",
            "60000/60000 - 2s - loss: 2.7659e-04 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9920\n",
            "Epoch 24/200\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "60000/60000 - 2s - loss: 2.7634e-04 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9920\n",
            "Epoch 25/200\n",
            "60000/60000 - 2s - loss: 2.7612e-04 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9920\n",
            "Epoch 00025: early stopping\n",
            "10000/10000 - 0s - loss: 0.0449 - accuracy: 0.9920\n",
            "model loss after retraining:  [0.044860158809653536, 0.992] \n",
            "\n",
            "Deleting 35/201 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.0441 - accuracy: 0.9920\n",
            "model loss after pruning:  [0.04405543050774436, 0.992] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0535 - val_accuracy: 0.9920\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0574 - val_accuracy: 0.9908\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 8.2408e-04 - accuracy: 0.9998 - val_loss: 0.0465 - val_accuracy: 0.9920\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 3.2925e-04 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9927\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 2.7461e-04 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9924\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 2.7218e-04 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9927\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 2.7129e-04 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9926\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 2.7072e-04 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9929\n",
            "Epoch 9/200\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 2.7031e-04 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9929\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 2.7005e-04 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9929\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 2.7002e-04 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9929\n",
            "Epoch 12/200\n",
            "60000/60000 - 2s - loss: 2.6998e-04 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9928\n",
            "Epoch 13/200\n",
            "60000/60000 - 2s - loss: 2.6994e-04 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9928\n",
            "Epoch 14/200\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 2.6989e-04 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9928\n",
            "Epoch 15/200\n",
            "60000/60000 - 2s - loss: 2.6985e-04 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9928\n",
            "Epoch 00015: early stopping\n",
            "10000/10000 - 0s - loss: 0.0459 - accuracy: 0.9928\n",
            "model loss after retraining:  [0.04594575916170618, 0.9928] \n",
            "\n",
            "Deleting 29/166 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.0448 - accuracy: 0.9927\n",
            "model loss after pruning:  [0.04484301379481023, 0.9927] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0633 - val_accuracy: 0.9909\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0527 - val_accuracy: 0.9917\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 9.4983e-04 - accuracy: 0.9998 - val_loss: 0.0476 - val_accuracy: 0.9917\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 3.5345e-04 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9926\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 3.6433e-04 - accuracy: 0.9999 - val_loss: 0.0486 - val_accuracy: 0.9924\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 2.7675e-04 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9920\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 2.7215e-04 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9922\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 2.7069e-04 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9924\n",
            "Epoch 9/200\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 2.7024e-04 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9925\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 2.6997e-04 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9925\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 2.6995e-04 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9925\n",
            "Epoch 12/200\n",
            "60000/60000 - 2s - loss: 2.6991e-04 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9925\n",
            "Epoch 13/200\n",
            "60000/60000 - 2s - loss: 2.6988e-04 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 0.9925\n",
            "Epoch 14/200\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 2.6983e-04 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 0.9925\n",
            "Epoch 00014: early stopping\n",
            "10000/10000 - 0s - loss: 0.0491 - accuracy: 0.9925\n",
            "model loss after retraining:  [0.049122682931543774, 0.9925] \n",
            "\n",
            "Deleting 19/137 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.0476 - accuracy: 0.9919\n",
            "model loss after pruning:  [0.047638266815068366, 0.9919] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0558 - val_accuracy: 0.9911\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 7.8515e-04 - accuracy: 0.9998 - val_loss: 0.0505 - val_accuracy: 0.9918\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 3.0449e-04 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9919\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 2.7349e-04 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9916\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 2.7220e-04 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9919\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 2.7145e-04 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9919\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 2.7091e-04 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9919\n",
            "Epoch 8/200\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 2.7049e-04 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9919\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 2.7021e-04 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9919\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 2.7018e-04 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9919\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 2.7014e-04 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9919\n",
            "Epoch 12/200\n",
            "60000/60000 - 2s - loss: 2.7009e-04 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9919\n",
            "Epoch 13/200\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 2.7004e-04 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9919\n",
            "Epoch 00013: early stopping\n",
            "10000/10000 - 0s - loss: 0.0508 - accuracy: 0.9919\n",
            "model loss after retraining:  [0.05081212982483014, 0.9919] \n",
            "\n",
            "Deleting 21/118 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.0585 - accuracy: 0.9890\n",
            "model loss after pruning:  [0.0585240973739114, 0.989] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0460 - val_accuracy: 0.9913\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0491 - val_accuracy: 0.9914\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0443 - val_accuracy: 0.9909\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 7.4627e-04 - accuracy: 0.9999 - val_loss: 0.0530 - val_accuracy: 0.9905\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 8.7648e-04 - accuracy: 0.9998 - val_loss: 0.0521 - val_accuracy: 0.9908\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0564 - val_accuracy: 0.9905\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0513 - val_accuracy: 0.9911\n",
            "Epoch 8/200\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0480 - val_accuracy: 0.9917\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 3.4603e-04 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9917\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 2.9653e-04 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9920\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 2.9082e-04 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9920\n",
            "Epoch 12/200\n",
            "60000/60000 - 2s - loss: 2.8699e-04 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9919\n",
            "Epoch 13/200\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 2.8418e-04 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9919\n",
            "Epoch 00013: early stopping\n",
            "10000/10000 - 0s - loss: 0.0464 - accuracy: 0.9919\n",
            "model loss after retraining:  [0.04638911582470903, 0.9919] \n",
            "\n",
            "Deleting 15/97 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.0508 - accuracy: 0.9900\n",
            "model loss after pruning:  [0.05076063212233171, 0.99] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0498 - val_accuracy: 0.9906\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 4.7286e-04 - accuracy: 0.9999 - val_loss: 0.0458 - val_accuracy: 0.9923\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 2.8187e-04 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9923\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 2.7557e-04 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9926\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 2.7375e-04 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9926\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 2.7250e-04 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9928\n",
            "Epoch 7/200\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 2.7163e-04 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.9928\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 2.7114e-04 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.9928\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 2.7106e-04 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9927\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 2.7098e-04 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9927\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 2.7089e-04 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9927\n",
            "Epoch 12/200\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 2.7079e-04 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 0.9927\n",
            "Epoch 00012: early stopping\n",
            "10000/10000 - 0s - loss: 0.0479 - accuracy: 0.9927\n",
            "model loss after retraining:  [0.04789997187954361, 0.9927] \n",
            "\n",
            "Deleting 11/82 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.0595 - accuracy: 0.9889\n",
            "model loss after pruning:  [0.05951078195124369, 0.9889] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0582 - val_accuracy: 0.9901\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 9.0364e-04 - accuracy: 0.9998 - val_loss: 0.0521 - val_accuracy: 0.9919\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 3.9974e-04 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9924\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 2.8570e-04 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9927\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 2.7632e-04 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9926\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 2.7371e-04 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 0.9929\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 2.7254e-04 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9929\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 2.7174e-04 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9932\n",
            "Epoch 9/200\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 2.7109e-04 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9932\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 2.7069e-04 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9932\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 2.7064e-04 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9933\n",
            "Epoch 12/200\n",
            "60000/60000 - 2s - loss: 2.7058e-04 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9934\n",
            "Epoch 13/200\n",
            "60000/60000 - 2s - loss: 2.7051e-04 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9934\n",
            "Epoch 14/200\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 2.7043e-04 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9934\n",
            "Epoch 00014: early stopping\n",
            "10000/10000 - 0s - loss: 0.0506 - accuracy: 0.9934\n",
            "model loss after retraining:  [0.05057558398079566, 0.9934] \n",
            "\n",
            "Deleting 11/71 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.0732 - accuracy: 0.9893\n",
            "model loss after pruning:  [0.07319536999703471, 0.9893] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0514 - val_accuracy: 0.9910\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0475 - val_accuracy: 0.9910\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 9.5140e-04 - accuracy: 0.9998 - val_loss: 0.0496 - val_accuracy: 0.9924\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 4.8220e-04 - accuracy: 0.9999 - val_loss: 0.0525 - val_accuracy: 0.9927\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0443 - val_accuracy: 0.9917\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0478 - val_accuracy: 0.9918\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 3.6271e-04 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 0.9924\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 2.8605e-04 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9925\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 2.7872e-04 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9927\n",
            "Epoch 10/200\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 2.7646e-04 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 0.9926\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 2.7496e-04 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9926\n",
            "Epoch 12/200\n",
            "60000/60000 - 2s - loss: 2.7479e-04 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9926\n",
            "Epoch 13/200\n",
            "60000/60000 - 2s - loss: 2.7460e-04 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 0.9926\n",
            "Epoch 14/200\n",
            "60000/60000 - 2s - loss: 2.7437e-04 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9926\n",
            "Epoch 15/200\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 2.7412e-04 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9926\n",
            "Epoch 00015: early stopping\n",
            "10000/10000 - 0s - loss: 0.0487 - accuracy: 0.9926\n",
            "model loss after retraining:  [0.0486960022485506, 0.9926] \n",
            "\n",
            "Deleting 9/60 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.0554 - accuracy: 0.9898\n",
            "model loss after pruning:  [0.0553847868665973, 0.9898] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0485 - val_accuracy: 0.9901\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 6.1650e-04 - accuracy: 0.9999 - val_loss: 0.0458 - val_accuracy: 0.9920\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 4.5910e-04 - accuracy: 0.9999 - val_loss: 0.0464 - val_accuracy: 0.9915\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 3.8566e-04 - accuracy: 0.9999 - val_loss: 0.0465 - val_accuracy: 0.9923\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 2.8983e-04 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9922\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 2.7566e-04 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9919\n",
            "Epoch 7/200\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 2.7365e-04 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 0.9920\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 2.7272e-04 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9920\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 2.7259e-04 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9920\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 2.7246e-04 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9920\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 2.7230e-04 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9920\n",
            "Epoch 12/200\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 2.7215e-04 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9919\n",
            "Epoch 00012: early stopping\n",
            "10000/10000 - 0s - loss: 0.0492 - accuracy: 0.9919\n",
            "model loss after retraining:  [0.04919586353300295, 0.9919] \n",
            "\n",
            "Deleting 9/51 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.0862 - accuracy: 0.9852\n",
            "model loss after pruning:  [0.08622077368946048, 0.9852] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0492 - val_accuracy: 0.9902\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 5.5209e-04 - accuracy: 0.9999 - val_loss: 0.0557 - val_accuracy: 0.9898\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0577 - val_accuracy: 0.9906\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0538 - val_accuracy: 0.9910\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 3.9651e-04 - accuracy: 0.9999 - val_loss: 0.0551 - val_accuracy: 0.9911\n",
            "Epoch 6/200\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 3.0675e-04 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9919\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 2.8147e-04 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9920\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 2.8051e-04 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9920\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 2.7971e-04 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9920\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 2.7897e-04 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9920\n",
            "Epoch 11/200\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 2.7825e-04 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9921\n",
            "Epoch 00011: early stopping\n",
            "10000/10000 - 0s - loss: 0.0528 - accuracy: 0.9921\n",
            "model loss after retraining:  [0.05283025599680734, 0.9921] \n",
            "\n",
            "Deleting 7/42 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.0661 - accuracy: 0.9866\n",
            "model loss after pruning:  [0.06610854459685352, 0.9866] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0462 - val_accuracy: 0.9907\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 6.9272e-04 - accuracy: 0.9999 - val_loss: 0.0530 - val_accuracy: 0.9909\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 3.7134e-04 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 0.9914\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0505 - val_accuracy: 0.9897\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0502 - val_accuracy: 0.9906\n",
            "Epoch 6/200\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0481 - val_accuracy: 0.9908\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 7.1655e-04 - accuracy: 0.9999 - val_loss: 0.0456 - val_accuracy: 0.9919\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 3.9496e-04 - accuracy: 0.9999 - val_loss: 0.0455 - val_accuracy: 0.9914\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 3.4089e-04 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9915\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 3.2155e-04 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9914\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 3.1088e-04 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9913\n",
            "Epoch 12/200\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 3.0346e-04 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9915\n",
            "Epoch 13/200\n",
            "60000/60000 - 2s - loss: 2.9876e-04 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9915\n",
            "Epoch 14/200\n",
            "60000/60000 - 2s - loss: 2.9817e-04 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9915\n",
            "Epoch 15/200\n",
            "60000/60000 - 2s - loss: 2.9748e-04 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9915\n",
            "Epoch 16/200\n",
            "60000/60000 - 2s - loss: 2.9667e-04 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9915\n",
            "Epoch 17/200\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "60000/60000 - 2s - loss: 2.9576e-04 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.9914\n",
            "Epoch 18/200\n",
            "60000/60000 - 2s - loss: 2.9490e-04 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.9914\n",
            "Epoch 00018: early stopping\n",
            "10000/10000 - 0s - loss: 0.0476 - accuracy: 0.9914\n",
            "model loss after retraining:  [0.04757506355028656, 0.9914] \n",
            "\n",
            "Deleting 5/35 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.0829 - accuracy: 0.9844\n",
            "model loss after pruning:  [0.08289895791507906, 0.9844] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.0596 - val_accuracy: 0.9896\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 9.6623e-04 - accuracy: 0.9998 - val_loss: 0.0491 - val_accuracy: 0.9907\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 9.8445e-04 - accuracy: 0.9998 - val_loss: 0.0583 - val_accuracy: 0.9890\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0536 - val_accuracy: 0.9903\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 5.0982e-04 - accuracy: 0.9999 - val_loss: 0.0514 - val_accuracy: 0.9902\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 3.1614e-04 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9901\n",
            "Epoch 7/200\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 2.8826e-04 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 0.9901\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 2.8321e-04 - accuracy: 1.0000 - val_loss: 0.0539 - val_accuracy: 0.9901\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 2.8271e-04 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 0.9901\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 2.8211e-04 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 0.9902\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 2.8146e-04 - accuracy: 1.0000 - val_loss: 0.0544 - val_accuracy: 0.9903\n",
            "Epoch 12/200\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 2.8078e-04 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 0.9905\n",
            "Epoch 00012: early stopping\n",
            "10000/10000 - 0s - loss: 0.0545 - accuracy: 0.9905\n",
            "model loss after retraining:  [0.054483120232448, 0.9905] \n",
            "\n",
            "Deleting 5/30 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.0950 - accuracy: 0.9812\n",
            "model loss after pruning:  [0.09495860747680562, 0.9812] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0520 - val_accuracy: 0.9897\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 9.1296e-04 - accuracy: 0.9998 - val_loss: 0.0562 - val_accuracy: 0.9896\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 9.9326e-04 - accuracy: 0.9998 - val_loss: 0.0536 - val_accuracy: 0.9910\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 5.2265e-04 - accuracy: 0.9999 - val_loss: 0.0591 - val_accuracy: 0.9900\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 3.5169e-04 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 0.9907\n",
            "Epoch 6/200\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 2.9521e-04 - accuracy: 1.0000 - val_loss: 0.0549 - val_accuracy: 0.9907\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 2.8736e-04 - accuracy: 1.0000 - val_loss: 0.0551 - val_accuracy: 0.9907\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 2.8663e-04 - accuracy: 1.0000 - val_loss: 0.0553 - val_accuracy: 0.9907\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 2.8589e-04 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 0.9907\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 2.8510e-04 - accuracy: 1.0000 - val_loss: 0.0557 - val_accuracy: 0.9907\n",
            "Epoch 11/200\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 2.8424e-04 - accuracy: 1.0000 - val_loss: 0.0560 - val_accuracy: 0.9907\n",
            "Epoch 00011: early stopping\n",
            "10000/10000 - 0s - loss: 0.0560 - accuracy: 0.9907\n",
            "model loss after retraining:  [0.05599034276987115, 0.9907] \n",
            "\n",
            "Deleting 3/25 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.0970 - accuracy: 0.9836\n",
            "model loss after pruning:  [0.09698886168191093, 0.9836] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0500 - val_accuracy: 0.9898\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0547 - val_accuracy: 0.9896\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 5.0389e-04 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9905\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 5.5113e-04 - accuracy: 0.9999 - val_loss: 0.0508 - val_accuracy: 0.9913\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 3.1327e-04 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9913\n",
            "Epoch 6/200\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 2.9435e-04 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9912\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 2.8761e-04 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9913\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 2.8698e-04 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9912\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 2.8633e-04 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9912\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 2.8565e-04 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9911\n",
            "Epoch 11/200\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 2.8487e-04 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9912\n",
            "Epoch 00011: early stopping\n",
            "10000/10000 - 0s - loss: 0.0527 - accuracy: 0.9912\n",
            "model loss after retraining:  [0.0527223713626807, 0.9912] \n",
            "\n",
            "Deleting 5/22 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.1893 - accuracy: 0.9664\n",
            "model loss after pruning:  [0.18929482678435744, 0.9664] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.0522 - val_accuracy: 0.9894\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0471 - val_accuracy: 0.9886\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 8.3354e-04 - accuracy: 0.9999 - val_loss: 0.0487 - val_accuracy: 0.9900\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 4.6018e-04 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 0.9900\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 3.8033e-04 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9898\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 3.4946e-04 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9909\n",
            "Epoch 7/200\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 3.2730e-04 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9908\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 3.1269e-04 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9906\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 3.1004e-04 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9906\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 3.0834e-04 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9906\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 3.0670e-04 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9906\n",
            "Epoch 12/200\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 3.0485e-04 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9905\n",
            "Epoch 00012: early stopping\n",
            "10000/10000 - 0s - loss: 0.0524 - accuracy: 0.9905\n",
            "model loss after retraining:  [0.052379103635477486, 0.9905] \n",
            "\n",
            "Deleting 1/17 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.0835 - accuracy: 0.9836\n",
            "model loss after pruning:  [0.08354215757117964, 0.9836] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0571 - val_accuracy: 0.9888\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 9.7212e-04 - accuracy: 0.9999 - val_loss: 0.0534 - val_accuracy: 0.9899\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 5.0049e-04 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9903\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 3.4698e-04 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 0.9904\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 3.2108e-04 - accuracy: 1.0000 - val_loss: 0.0549 - val_accuracy: 0.9905\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 3.0756e-04 - accuracy: 1.0000 - val_loss: 0.0563 - val_accuracy: 0.9905\n",
            "Epoch 7/200\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 2.9859e-04 - accuracy: 1.0000 - val_loss: 0.0570 - val_accuracy: 0.9902\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 2.9177e-04 - accuracy: 1.0000 - val_loss: 0.0571 - val_accuracy: 0.9901\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 2.9091e-04 - accuracy: 1.0000 - val_loss: 0.0572 - val_accuracy: 0.9903\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 2.9011e-04 - accuracy: 1.0000 - val_loss: 0.0574 - val_accuracy: 0.9903\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 2.8927e-04 - accuracy: 1.0000 - val_loss: 0.0574 - val_accuracy: 0.9904\n",
            "Epoch 12/200\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 2.8837e-04 - accuracy: 1.0000 - val_loss: 0.0579 - val_accuracy: 0.9903\n",
            "Epoch 00012: early stopping\n",
            "10000/10000 - 0s - loss: 0.0579 - accuracy: 0.9903\n",
            "model loss after retraining:  [0.05786554802122539, 0.9903] \n",
            "\n",
            "Deleting 1/16 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.0887 - accuracy: 0.9844\n",
            "model loss after pruning:  [0.08872058682817424, 0.9844] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0528 - val_accuracy: 0.9901\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0607 - val_accuracy: 0.9894\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 8.3881e-04 - accuracy: 0.9998 - val_loss: 0.0530 - val_accuracy: 0.9908\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 4.6344e-04 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9910\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 3.4405e-04 - accuracy: 1.0000 - val_loss: 0.0552 - val_accuracy: 0.9905\n",
            "Epoch 6/200\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 3.1095e-04 - accuracy: 1.0000 - val_loss: 0.0553 - val_accuracy: 0.9910\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 2.9822e-04 - accuracy: 1.0000 - val_loss: 0.0555 - val_accuracy: 0.9911\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 2.9666e-04 - accuracy: 1.0000 - val_loss: 0.0557 - val_accuracy: 0.9910\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 2.9560e-04 - accuracy: 1.0000 - val_loss: 0.0559 - val_accuracy: 0.9910\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 2.9456e-04 - accuracy: 1.0000 - val_loss: 0.0560 - val_accuracy: 0.9911\n",
            "Epoch 11/200\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 2.9346e-04 - accuracy: 1.0000 - val_loss: 0.0562 - val_accuracy: 0.9911\n",
            "Epoch 00011: early stopping\n",
            "10000/10000 - 0s - loss: 0.0562 - accuracy: 0.9911\n",
            "model loss after retraining:  [0.05621758349491668, 0.9911] \n",
            "\n",
            "Deleting 1/15 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.1290 - accuracy: 0.9771\n",
            "model loss after pruning:  [0.12903195133494447, 0.9771] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.0569 - val_accuracy: 0.9894\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0592 - val_accuracy: 0.9896\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 7.4338e-04 - accuracy: 0.9999 - val_loss: 0.0519 - val_accuracy: 0.9903\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 4.2416e-04 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9901\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 3.4019e-04 - accuracy: 1.0000 - val_loss: 0.0546 - val_accuracy: 0.9903\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 3.1683e-04 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 0.9903\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 3.0465e-04 - accuracy: 1.0000 - val_loss: 0.0547 - val_accuracy: 0.9904\n",
            "Epoch 8/200\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 2.9645e-04 - accuracy: 1.0000 - val_loss: 0.0554 - val_accuracy: 0.9904\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 2.9083e-04 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 0.9907\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 2.8971e-04 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 0.9907\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 2.8897e-04 - accuracy: 1.0000 - val_loss: 0.0558 - val_accuracy: 0.9907\n",
            "Epoch 12/200\n",
            "60000/60000 - 2s - loss: 2.8831e-04 - accuracy: 1.0000 - val_loss: 0.0559 - val_accuracy: 0.9906\n",
            "Epoch 13/200\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 2.8756e-04 - accuracy: 1.0000 - val_loss: 0.0562 - val_accuracy: 0.9906\n",
            "Epoch 00013: early stopping\n",
            "10000/10000 - 0s - loss: 0.0562 - accuracy: 0.9906\n",
            "model loss after retraining:  [0.05617014943646539, 0.9906] \n",
            "\n",
            "Deleting 2/14 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.2349 - accuracy: 0.9588\n",
            "model loss after pruning:  [0.23486739161564038, 0.9588] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.0595 - val_accuracy: 0.9884\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0546 - val_accuracy: 0.9885\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0584 - val_accuracy: 0.9897\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 8.7034e-04 - accuracy: 0.9999 - val_loss: 0.0554 - val_accuracy: 0.9892\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0642 - val_accuracy: 0.9889\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0622 - val_accuracy: 0.9899\n",
            "Epoch 7/200\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0588 - val_accuracy: 0.9893\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 5.3955e-04 - accuracy: 1.0000 - val_loss: 0.0559 - val_accuracy: 0.9904\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 4.2571e-04 - accuracy: 1.0000 - val_loss: 0.0560 - val_accuracy: 0.9906\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 4.0562e-04 - accuracy: 1.0000 - val_loss: 0.0562 - val_accuracy: 0.9905\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 3.9054e-04 - accuracy: 1.0000 - val_loss: 0.0565 - val_accuracy: 0.9905\n",
            "Epoch 12/200\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 3.7782e-04 - accuracy: 1.0000 - val_loss: 0.0571 - val_accuracy: 0.9901\n",
            "Epoch 00012: early stopping\n",
            "10000/10000 - 0s - loss: 0.0571 - accuracy: 0.9901\n",
            "model loss after retraining:  [0.05710491200202905, 0.9901] \n",
            "\n",
            "Deleting 2/12 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.5564 - accuracy: 0.9107\n",
            "model loss after pruning:  [0.5564356766700744, 0.9107] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0205 - accuracy: 0.9942 - val_loss: 0.0584 - val_accuracy: 0.9863\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0605 - val_accuracy: 0.9864\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0603 - val_accuracy: 0.9864\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0620 - val_accuracy: 0.9882\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0622 - val_accuracy: 0.9879\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0580 - val_accuracy: 0.9878\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0648 - val_accuracy: 0.9876\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0681 - val_accuracy: 0.9873\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0650 - val_accuracy: 0.9872\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0692 - val_accuracy: 0.9878\n",
            "Epoch 11/200\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0632 - val_accuracy: 0.9890\n",
            "Epoch 12/200\n",
            "60000/60000 - 2s - loss: 5.7473e-04 - accuracy: 0.9999 - val_loss: 0.0625 - val_accuracy: 0.9893\n",
            "Epoch 13/200\n",
            "60000/60000 - 2s - loss: 4.4780e-04 - accuracy: 1.0000 - val_loss: 0.0620 - val_accuracy: 0.9892\n",
            "Epoch 14/200\n",
            "60000/60000 - 2s - loss: 4.0615e-04 - accuracy: 1.0000 - val_loss: 0.0622 - val_accuracy: 0.9891\n",
            "Epoch 15/200\n",
            "60000/60000 - 2s - loss: 3.8793e-04 - accuracy: 1.0000 - val_loss: 0.0626 - val_accuracy: 0.9892\n",
            "Epoch 16/200\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 3.7468e-04 - accuracy: 1.0000 - val_loss: 0.0626 - val_accuracy: 0.9892\n",
            "Epoch 00016: early stopping\n",
            "10000/10000 - 0s - loss: 0.0626 - accuracy: 0.9892\n",
            "model loss after retraining:  [0.06260568095642462, 0.9892] \n",
            "\n",
            "Deleting 1/10 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.1901 - accuracy: 0.9614\n",
            "model loss after pruning:  [0.19009262727871537, 0.9614] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.0563 - val_accuracy: 0.9880\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0601 - val_accuracy: 0.9888\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0636 - val_accuracy: 0.9883\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0573 - val_accuracy: 0.9892\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0677 - val_accuracy: 0.9870\n",
            "Epoch 6/200\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0635 - val_accuracy: 0.9887\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 7.1826e-04 - accuracy: 0.9999 - val_loss: 0.0633 - val_accuracy: 0.9888\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 5.2669e-04 - accuracy: 1.0000 - val_loss: 0.0637 - val_accuracy: 0.9888\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 4.7545e-04 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 0.9889\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 4.4677e-04 - accuracy: 1.0000 - val_loss: 0.0643 - val_accuracy: 0.9889\n",
            "Epoch 11/200\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 4.2505e-04 - accuracy: 1.0000 - val_loss: 0.0650 - val_accuracy: 0.9890\n",
            "Epoch 00011: early stopping\n",
            "10000/10000 - 0s - loss: 0.0650 - accuracy: 0.9890\n",
            "model loss after retraining:  [0.06502009985457918, 0.989] \n",
            "\n",
            "Deleting 1/9 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.2501 - accuracy: 0.9543\n",
            "model loss after pruning:  [0.25005962451946395, 0.9543] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.0636 - val_accuracy: 0.9868\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.0615 - val_accuracy: 0.9872\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0599 - val_accuracy: 0.9873\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0664 - val_accuracy: 0.9862\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0650 - val_accuracy: 0.9879\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0626 - val_accuracy: 0.9882\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0642 - val_accuracy: 0.9876\n",
            "Epoch 8/200\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0635 - val_accuracy: 0.9882\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 7.5666e-04 - accuracy: 0.9999 - val_loss: 0.0615 - val_accuracy: 0.9890\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 5.8408e-04 - accuracy: 1.0000 - val_loss: 0.0607 - val_accuracy: 0.9898\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 5.3876e-04 - accuracy: 1.0000 - val_loss: 0.0605 - val_accuracy: 0.9897\n",
            "Epoch 12/200\n",
            "60000/60000 - 2s - loss: 5.0755e-04 - accuracy: 1.0000 - val_loss: 0.0605 - val_accuracy: 0.9899\n",
            "Epoch 13/200\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 4.8463e-04 - accuracy: 1.0000 - val_loss: 0.0608 - val_accuracy: 0.9900\n",
            "Epoch 00013: early stopping\n",
            "10000/10000 - 0s - loss: 0.0608 - accuracy: 0.9900\n",
            "model loss after retraining:  [0.06081126274567378, 0.99] \n",
            "\n",
            "Deleting 2/8 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 2.3500 - accuracy: 0.6033\n",
            "model loss after pruning:  [2.349984461593628, 0.6033] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.1225 - accuracy: 0.9688 - val_loss: 0.0996 - val_accuracy: 0.9764\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 0.0356 - accuracy: 0.9890 - val_loss: 0.0825 - val_accuracy: 0.9792\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 0.0251 - accuracy: 0.9922 - val_loss: 0.0777 - val_accuracy: 0.9807\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 0.0188 - accuracy: 0.9942 - val_loss: 0.0774 - val_accuracy: 0.9817\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 0.0151 - accuracy: 0.9954 - val_loss: 0.0782 - val_accuracy: 0.9829\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 0.0124 - accuracy: 0.9960 - val_loss: 0.0761 - val_accuracy: 0.9830\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 0.0093 - accuracy: 0.9973 - val_loss: 0.0742 - val_accuracy: 0.9835\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.0761 - val_accuracy: 0.9834\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.0786 - val_accuracy: 0.9833\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0774 - val_accuracy: 0.9848\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.0782 - val_accuracy: 0.9840\n",
            "Epoch 12/200\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.0825 - val_accuracy: 0.9854\n",
            "Epoch 13/200\n",
            "60000/60000 - 2s - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.0786 - val_accuracy: 0.9853\n",
            "Epoch 14/200\n",
            "60000/60000 - 2s - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.0774 - val_accuracy: 0.9856\n",
            "Epoch 15/200\n",
            "60000/60000 - 2s - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.0777 - val_accuracy: 0.9859\n",
            "Epoch 16/200\n",
            "60000/60000 - 2s - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0780 - val_accuracy: 0.9859\n",
            "Epoch 17/200\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0784 - val_accuracy: 0.9856\n",
            "Epoch 00017: early stopping\n",
            "10000/10000 - 0s - loss: 0.0784 - accuracy: 0.9856\n",
            "model loss after retraining:  [0.07835116937581915, 0.9856] \n",
            "\n",
            "Deleting 1/6 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 1.6799 - accuracy: 0.7075\n",
            "model loss after pruning:  [1.6799156074523927, 0.7075] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0927 - accuracy: 0.9744 - val_loss: 0.0925 - val_accuracy: 0.9754\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 0.0317 - accuracy: 0.9894 - val_loss: 0.0869 - val_accuracy: 0.9791\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 0.0232 - accuracy: 0.9923 - val_loss: 0.0808 - val_accuracy: 0.9805\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.0811 - val_accuracy: 0.9807\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.0821 - val_accuracy: 0.9810\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 0.0127 - accuracy: 0.9964 - val_loss: 0.0823 - val_accuracy: 0.9807\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.0805 - val_accuracy: 0.9816\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.0854 - val_accuracy: 0.9823\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.0957 - val_accuracy: 0.9810\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.0865 - val_accuracy: 0.9831\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0887 - val_accuracy: 0.9810\n",
            "Epoch 12/200\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.0986 - val_accuracy: 0.9811\n",
            "Epoch 13/200\n",
            "60000/60000 - 2s - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0878 - val_accuracy: 0.9832\n",
            "Epoch 14/200\n",
            "60000/60000 - 2s - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.0864 - val_accuracy: 0.9829\n",
            "Epoch 15/200\n",
            "60000/60000 - 2s - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0874 - val_accuracy: 0.9833\n",
            "Epoch 16/200\n",
            "60000/60000 - 2s - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0870 - val_accuracy: 0.9835\n",
            "Epoch 17/200\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 0.0024 - accuracy: 0.9998 - val_loss: 0.0866 - val_accuracy: 0.9833\n",
            "Epoch 00017: early stopping\n",
            "10000/10000 - 0s - loss: 0.0866 - accuracy: 0.9833\n",
            "model loss after retraining:  [0.08660638158118963, 0.9833] \n",
            "\n",
            "Deleting 1/5 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 5.0639 - accuracy: 0.4098\n",
            "model loss after pruning:  [5.063896890258789, 0.4098] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.4197 - accuracy: 0.8706 - val_loss: 0.1607 - val_accuracy: 0.9613\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 0.0800 - accuracy: 0.9740 - val_loss: 0.1366 - val_accuracy: 0.9659\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 0.0616 - accuracy: 0.9795 - val_loss: 0.1262 - val_accuracy: 0.9680\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 0.0522 - accuracy: 0.9832 - val_loss: 0.1186 - val_accuracy: 0.9717\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 0.0441 - accuracy: 0.9860 - val_loss: 0.1163 - val_accuracy: 0.9730\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 0.0392 - accuracy: 0.9874 - val_loss: 0.1173 - val_accuracy: 0.9723\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 0.0343 - accuracy: 0.9894 - val_loss: 0.1124 - val_accuracy: 0.9747\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 0.0308 - accuracy: 0.9909 - val_loss: 0.1142 - val_accuracy: 0.9739\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 0.0281 - accuracy: 0.9912 - val_loss: 0.1118 - val_accuracy: 0.9749\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 0.0253 - accuracy: 0.9928 - val_loss: 0.1155 - val_accuracy: 0.9750\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 0.0238 - accuracy: 0.9930 - val_loss: 0.1134 - val_accuracy: 0.9759\n",
            "Epoch 12/200\n",
            "60000/60000 - 2s - loss: 0.0214 - accuracy: 0.9941 - val_loss: 0.1079 - val_accuracy: 0.9765\n",
            "Epoch 13/200\n",
            "60000/60000 - 2s - loss: 0.0184 - accuracy: 0.9949 - val_loss: 0.1156 - val_accuracy: 0.9768\n",
            "Epoch 14/200\n",
            "60000/60000 - 2s - loss: 0.0173 - accuracy: 0.9951 - val_loss: 0.1132 - val_accuracy: 0.9768\n",
            "Epoch 15/200\n",
            "60000/60000 - 2s - loss: 0.0161 - accuracy: 0.9956 - val_loss: 0.1116 - val_accuracy: 0.9780\n",
            "Epoch 16/200\n",
            "60000/60000 - 2s - loss: 0.0146 - accuracy: 0.9961 - val_loss: 0.1203 - val_accuracy: 0.9760\n",
            "Epoch 17/200\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 0.0131 - accuracy: 0.9965 - val_loss: 0.1140 - val_accuracy: 0.9790\n",
            "Epoch 18/200\n",
            "60000/60000 - 2s - loss: 0.0087 - accuracy: 0.9981 - val_loss: 0.1124 - val_accuracy: 0.9789\n",
            "Epoch 19/200\n",
            "60000/60000 - 2s - loss: 0.0076 - accuracy: 0.9987 - val_loss: 0.1147 - val_accuracy: 0.9788\n",
            "Epoch 20/200\n",
            "60000/60000 - 2s - loss: 0.0073 - accuracy: 0.9989 - val_loss: 0.1150 - val_accuracy: 0.9783\n",
            "Epoch 21/200\n",
            "60000/60000 - 2s - loss: 0.0070 - accuracy: 0.9990 - val_loss: 0.1161 - val_accuracy: 0.9786\n",
            "Epoch 22/200\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 0.0067 - accuracy: 0.9990 - val_loss: 0.1172 - val_accuracy: 0.9781\n",
            "Epoch 00022: early stopping\n",
            "10000/10000 - 0s - loss: 0.1172 - accuracy: 0.9781\n",
            "model loss after retraining:  [0.11723930473127403, 0.9781] \n",
            "\n",
            "Deleting 1/4 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 5.0569 - accuracy: 0.5413\n",
            "model loss after pruning:  [5.056942905426025, 0.5413] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.7418 - accuracy: 0.7661 - val_loss: 0.3680 - val_accuracy: 0.8502\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 0.2647 - accuracy: 0.8740 - val_loss: 0.2753 - val_accuracy: 0.8985\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 0.1584 - accuracy: 0.9442 - val_loss: 0.1867 - val_accuracy: 0.9471\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 0.1181 - accuracy: 0.9616 - val_loss: 0.1739 - val_accuracy: 0.9526\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 0.1027 - accuracy: 0.9664 - val_loss: 0.1657 - val_accuracy: 0.9561\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 0.0928 - accuracy: 0.9710 - val_loss: 0.1681 - val_accuracy: 0.9559\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 0.0857 - accuracy: 0.9722 - val_loss: 0.1564 - val_accuracy: 0.9604\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 0.0790 - accuracy: 0.9754 - val_loss: 0.1572 - val_accuracy: 0.9608\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 0.0742 - accuracy: 0.9771 - val_loss: 0.1514 - val_accuracy: 0.9589\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 0.0696 - accuracy: 0.9782 - val_loss: 0.1484 - val_accuracy: 0.9631\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 0.0650 - accuracy: 0.9796 - val_loss: 0.1558 - val_accuracy: 0.9603\n",
            "Epoch 12/200\n",
            "60000/60000 - 2s - loss: 0.0625 - accuracy: 0.9804 - val_loss: 0.1505 - val_accuracy: 0.9620\n",
            "Epoch 13/200\n",
            "60000/60000 - 2s - loss: 0.0587 - accuracy: 0.9819 - val_loss: 0.1559 - val_accuracy: 0.9630\n",
            "Epoch 14/200\n",
            "60000/60000 - 2s - loss: 0.0562 - accuracy: 0.9827 - val_loss: 0.1477 - val_accuracy: 0.9640\n",
            "Epoch 15/200\n",
            "60000/60000 - 2s - loss: 0.0539 - accuracy: 0.9836 - val_loss: 0.1577 - val_accuracy: 0.9628\n",
            "Epoch 16/200\n",
            "60000/60000 - 2s - loss: 0.0513 - accuracy: 0.9840 - val_loss: 0.1539 - val_accuracy: 0.9632\n",
            "Epoch 17/200\n",
            "60000/60000 - 2s - loss: 0.0485 - accuracy: 0.9850 - val_loss: 0.1480 - val_accuracy: 0.9634\n",
            "Epoch 18/200\n",
            "60000/60000 - 2s - loss: 0.0467 - accuracy: 0.9857 - val_loss: 0.1619 - val_accuracy: 0.9626\n",
            "Epoch 19/200\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 0.0451 - accuracy: 0.9860 - val_loss: 0.1564 - val_accuracy: 0.9618\n",
            "Epoch 20/200\n",
            "60000/60000 - 2s - loss: 0.0361 - accuracy: 0.9902 - val_loss: 0.1520 - val_accuracy: 0.9645\n",
            "Epoch 21/200\n",
            "60000/60000 - 2s - loss: 0.0334 - accuracy: 0.9912 - val_loss: 0.1533 - val_accuracy: 0.9657\n",
            "Epoch 22/200\n",
            "60000/60000 - 2s - loss: 0.0327 - accuracy: 0.9916 - val_loss: 0.1523 - val_accuracy: 0.9648\n",
            "Epoch 23/200\n",
            "60000/60000 - 2s - loss: 0.0321 - accuracy: 0.9917 - val_loss: 0.1546 - val_accuracy: 0.9653\n",
            "Epoch 24/200\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 0.0318 - accuracy: 0.9919 - val_loss: 0.1542 - val_accuracy: 0.9652\n",
            "Epoch 00024: early stopping\n",
            "10000/10000 - 0s - loss: 0.1542 - accuracy: 0.9652\n",
            "model loss after retraining:  [0.15424224982708692, 0.9652] \n",
            "\n",
            "Deleting 0/3 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.1542 - accuracy: 0.9652\n",
            "model loss after pruning:  [0.15424224982708692, 0.9652] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0414 - accuracy: 0.9873 - val_loss: 0.1614 - val_accuracy: 0.9634\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 0.0398 - accuracy: 0.9879 - val_loss: 0.1615 - val_accuracy: 0.9628\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 0.0386 - accuracy: 0.9877 - val_loss: 0.1666 - val_accuracy: 0.9649\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 0.0364 - accuracy: 0.9891 - val_loss: 0.1609 - val_accuracy: 0.9646\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 0.0349 - accuracy: 0.9897 - val_loss: 0.1659 - val_accuracy: 0.9632\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 0.0331 - accuracy: 0.9900 - val_loss: 0.1721 - val_accuracy: 0.9625\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 0.0320 - accuracy: 0.9902 - val_loss: 0.1633 - val_accuracy: 0.9636\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 0.0299 - accuracy: 0.9910 - val_loss: 0.1773 - val_accuracy: 0.9627\n",
            "Epoch 9/200\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 0.0297 - accuracy: 0.9913 - val_loss: 0.1689 - val_accuracy: 0.9643\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 0.0217 - accuracy: 0.9948 - val_loss: 0.1687 - val_accuracy: 0.9645\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 0.0197 - accuracy: 0.9957 - val_loss: 0.1712 - val_accuracy: 0.9642\n",
            "Epoch 12/200\n",
            "60000/60000 - 2s - loss: 0.0191 - accuracy: 0.9961 - val_loss: 0.1728 - val_accuracy: 0.9634\n",
            "Epoch 13/200\n",
            "60000/60000 - 2s - loss: 0.0187 - accuracy: 0.9963 - val_loss: 0.1738 - val_accuracy: 0.9634\n",
            "Epoch 14/200\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 0.0185 - accuracy: 0.9963 - val_loss: 0.1736 - val_accuracy: 0.9637\n",
            "Epoch 00014: early stopping\n",
            "10000/10000 - 0s - loss: 0.1736 - accuracy: 0.9637\n",
            "model loss after retraining:  [0.1736367628850043, 0.9637] \n",
            "\n",
            "Deleting 0/3 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.1736 - accuracy: 0.9637\n",
            "model loss after pruning:  [0.1736367628850043, 0.9637] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0274 - accuracy: 0.9918 - val_loss: 0.1763 - val_accuracy: 0.9640\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 0.0261 - accuracy: 0.9927 - val_loss: 0.1842 - val_accuracy: 0.9630\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 0.0252 - accuracy: 0.9927 - val_loss: 0.1749 - val_accuracy: 0.9630\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 0.0240 - accuracy: 0.9928 - val_loss: 0.1835 - val_accuracy: 0.9629\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 0.0230 - accuracy: 0.9932 - val_loss: 0.1858 - val_accuracy: 0.9622\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 0.0211 - accuracy: 0.9945 - val_loss: 0.1843 - val_accuracy: 0.9631\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 0.0221 - accuracy: 0.9936 - val_loss: 0.1883 - val_accuracy: 0.9628\n",
            "Epoch 8/200\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 0.0218 - accuracy: 0.9934 - val_loss: 0.2012 - val_accuracy: 0.9601\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 0.0153 - accuracy: 0.9967 - val_loss: 0.1852 - val_accuracy: 0.9635\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 0.0131 - accuracy: 0.9980 - val_loss: 0.1873 - val_accuracy: 0.9629\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 0.0125 - accuracy: 0.9979 - val_loss: 0.1893 - val_accuracy: 0.9639\n",
            "Epoch 12/200\n",
            "60000/60000 - 2s - loss: 0.0122 - accuracy: 0.9980 - val_loss: 0.1908 - val_accuracy: 0.9634\n",
            "Epoch 13/200\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 0.0120 - accuracy: 0.9981 - val_loss: 0.1910 - val_accuracy: 0.9634\n",
            "Epoch 00013: early stopping\n",
            "10000/10000 - 0s - loss: 0.1910 - accuracy: 0.9634\n",
            "model loss after retraining:  [0.1910385066822171, 0.9634] \n",
            "\n",
            "Deleting 0/3 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 0.1910 - accuracy: 0.9634\n",
            "model loss after pruning:  [0.1910385066822171, 0.9634] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 0.0194 - accuracy: 0.9946 - val_loss: 0.1981 - val_accuracy: 0.9622\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 0.0190 - accuracy: 0.9945 - val_loss: 0.2034 - val_accuracy: 0.9627\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 0.0190 - accuracy: 0.9944 - val_loss: 0.2061 - val_accuracy: 0.9620\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 0.0182 - accuracy: 0.9949 - val_loss: 0.1948 - val_accuracy: 0.9641\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 0.0172 - accuracy: 0.9952 - val_loss: 0.2031 - val_accuracy: 0.9622\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 0.0165 - accuracy: 0.9957 - val_loss: 0.2135 - val_accuracy: 0.9618\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 0.0158 - accuracy: 0.9956 - val_loss: 0.2118 - val_accuracy: 0.9635\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 0.0179 - accuracy: 0.9948 - val_loss: 0.1981 - val_accuracy: 0.9615\n",
            "Epoch 9/200\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 0.0143 - accuracy: 0.9964 - val_loss: 0.2076 - val_accuracy: 0.9642\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 0.0096 - accuracy: 0.9984 - val_loss: 0.2060 - val_accuracy: 0.9648\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 0.0086 - accuracy: 0.9987 - val_loss: 0.2080 - val_accuracy: 0.9650\n",
            "Epoch 12/200\n",
            "60000/60000 - 2s - loss: 0.0082 - accuracy: 0.9988 - val_loss: 0.2095 - val_accuracy: 0.9647\n",
            "Epoch 13/200\n",
            "60000/60000 - 2s - loss: 0.0080 - accuracy: 0.9989 - val_loss: 0.2099 - val_accuracy: 0.9647\n",
            "Epoch 14/200\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 0.0078 - accuracy: 0.9989 - val_loss: 0.2122 - val_accuracy: 0.9646\n",
            "Epoch 00014: early stopping\n",
            "10000/10000 - 0s - loss: 0.2122 - accuracy: 0.9646\n",
            "model loss after retraining:  [0.2121843768686056, 0.9646] \n",
            "\n",
            "Deleting 1/3 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 9.0713 - accuracy: 0.3671\n",
            "model loss after pruning:  [9.07127017211914, 0.3671] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 2.7449 - accuracy: 0.4635 - val_loss: 1.7195 - val_accuracy: 0.5958\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 1.0270 - accuracy: 0.7020 - val_loss: 0.6542 - val_accuracy: 0.7864\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 0.4874 - accuracy: 0.8494 - val_loss: 0.5477 - val_accuracy: 0.8582\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 0.4158 - accuracy: 0.8814 - val_loss: 0.4849 - val_accuracy: 0.8846\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 0.3667 - accuracy: 0.9028 - val_loss: 0.4594 - val_accuracy: 0.8951\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 0.3301 - accuracy: 0.9146 - val_loss: 0.4098 - val_accuracy: 0.9039\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 0.3027 - accuracy: 0.9224 - val_loss: 0.3937 - val_accuracy: 0.9097\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 0.2808 - accuracy: 0.9265 - val_loss: 0.3846 - val_accuracy: 0.9123\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 0.2646 - accuracy: 0.9310 - val_loss: 0.3678 - val_accuracy: 0.9149\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 0.2515 - accuracy: 0.9343 - val_loss: 0.3537 - val_accuracy: 0.9149\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 0.2391 - accuracy: 0.9365 - val_loss: 0.3465 - val_accuracy: 0.9184\n",
            "Epoch 12/200\n",
            "60000/60000 - 2s - loss: 0.2298 - accuracy: 0.9393 - val_loss: 0.3322 - val_accuracy: 0.9200\n",
            "Epoch 13/200\n",
            "60000/60000 - 2s - loss: 0.2198 - accuracy: 0.9420 - val_loss: 0.3294 - val_accuracy: 0.9241\n",
            "Epoch 14/200\n",
            "60000/60000 - 2s - loss: 0.2114 - accuracy: 0.9443 - val_loss: 0.3306 - val_accuracy: 0.9240\n",
            "Epoch 15/200\n",
            "60000/60000 - 2s - loss: 0.2033 - accuracy: 0.9464 - val_loss: 0.3263 - val_accuracy: 0.9237\n",
            "Epoch 16/200\n",
            "60000/60000 - 2s - loss: 0.1967 - accuracy: 0.9475 - val_loss: 0.3147 - val_accuracy: 0.9282\n",
            "Epoch 17/200\n",
            "60000/60000 - 2s - loss: 0.1897 - accuracy: 0.9491 - val_loss: 0.3080 - val_accuracy: 0.9312\n",
            "Epoch 18/200\n",
            "60000/60000 - 2s - loss: 0.1851 - accuracy: 0.9512 - val_loss: 0.3093 - val_accuracy: 0.9316\n",
            "Epoch 19/200\n",
            "60000/60000 - 2s - loss: 0.1783 - accuracy: 0.9518 - val_loss: 0.3310 - val_accuracy: 0.9260\n",
            "Epoch 20/200\n",
            "60000/60000 - 2s - loss: 0.1748 - accuracy: 0.9529 - val_loss: 0.3059 - val_accuracy: 0.9313\n",
            "Epoch 21/200\n",
            "60000/60000 - 2s - loss: 0.1685 - accuracy: 0.9545 - val_loss: 0.3036 - val_accuracy: 0.9325\n",
            "Epoch 22/200\n",
            "60000/60000 - 2s - loss: 0.1648 - accuracy: 0.9554 - val_loss: 0.3049 - val_accuracy: 0.9336\n",
            "Epoch 23/200\n",
            "60000/60000 - 2s - loss: 0.1611 - accuracy: 0.9561 - val_loss: 0.3058 - val_accuracy: 0.9325\n",
            "Epoch 24/200\n",
            "60000/60000 - 2s - loss: 0.1583 - accuracy: 0.9569 - val_loss: 0.3078 - val_accuracy: 0.9346\n",
            "Epoch 25/200\n",
            "60000/60000 - 2s - loss: 0.1555 - accuracy: 0.9576 - val_loss: 0.3014 - val_accuracy: 0.9356\n",
            "Epoch 26/200\n",
            "60000/60000 - 2s - loss: 0.1509 - accuracy: 0.9595 - val_loss: 0.3034 - val_accuracy: 0.9344\n",
            "Epoch 27/200\n",
            "60000/60000 - 2s - loss: 0.1497 - accuracy: 0.9589 - val_loss: 0.3001 - val_accuracy: 0.9355\n",
            "Epoch 28/200\n",
            "60000/60000 - 2s - loss: 0.1456 - accuracy: 0.9602 - val_loss: 0.3031 - val_accuracy: 0.9374\n",
            "Epoch 29/200\n",
            "60000/60000 - 2s - loss: 0.1418 - accuracy: 0.9614 - val_loss: 0.2998 - val_accuracy: 0.9349\n",
            "Epoch 30/200\n",
            "60000/60000 - 2s - loss: 0.1402 - accuracy: 0.9614 - val_loss: 0.3065 - val_accuracy: 0.9367\n",
            "Epoch 31/200\n",
            "60000/60000 - 2s - loss: 0.1387 - accuracy: 0.9622 - val_loss: 0.2950 - val_accuracy: 0.9385\n",
            "Epoch 32/200\n",
            "60000/60000 - 2s - loss: 0.1351 - accuracy: 0.9634 - val_loss: 0.3037 - val_accuracy: 0.9372\n",
            "Epoch 33/200\n",
            "60000/60000 - 2s - loss: 0.1330 - accuracy: 0.9641 - val_loss: 0.2966 - val_accuracy: 0.9369\n",
            "Epoch 34/200\n",
            "60000/60000 - 2s - loss: 0.1312 - accuracy: 0.9638 - val_loss: 0.3036 - val_accuracy: 0.9361\n",
            "Epoch 35/200\n",
            "60000/60000 - 2s - loss: 0.1287 - accuracy: 0.9644 - val_loss: 0.3028 - val_accuracy: 0.9360\n",
            "Epoch 36/200\n",
            "\n",
            "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 0.1273 - accuracy: 0.9648 - val_loss: 0.3078 - val_accuracy: 0.9372\n",
            "Epoch 37/200\n",
            "60000/60000 - 2s - loss: 0.1133 - accuracy: 0.9700 - val_loss: 0.3038 - val_accuracy: 0.9379\n",
            "Epoch 38/200\n",
            "60000/60000 - 2s - loss: 0.1103 - accuracy: 0.9708 - val_loss: 0.3070 - val_accuracy: 0.9382\n",
            "Epoch 39/200\n",
            "60000/60000 - 2s - loss: 0.1092 - accuracy: 0.9715 - val_loss: 0.3050 - val_accuracy: 0.9381\n",
            "Epoch 40/200\n",
            "60000/60000 - 2s - loss: 0.1086 - accuracy: 0.9721 - val_loss: 0.3063 - val_accuracy: 0.9379\n",
            "Epoch 41/200\n",
            "\n",
            "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 0.1080 - accuracy: 0.9722 - val_loss: 0.3085 - val_accuracy: 0.9375\n",
            "Epoch 00041: early stopping\n",
            "10000/10000 - 0s - loss: 0.3085 - accuracy: 0.9375\n",
            "model loss after retraining:  [0.3084846363425255, 0.9375] \n",
            "\n",
            "Deleting 1/2 channels from layer: dense_1\n",
            "10000/10000 - 0s - loss: 10.2983 - accuracy: 0.1856\n",
            "model loss after pruning:  [10.298346755981445, 0.1856] \n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 - 2s - loss: 5.9562 - accuracy: 0.2670 - val_loss: 5.1697 - val_accuracy: 0.3341\n",
            "Epoch 2/200\n",
            "60000/60000 - 2s - loss: 4.5822 - accuracy: 0.3388 - val_loss: 4.1047 - val_accuracy: 0.3349\n",
            "Epoch 3/200\n",
            "60000/60000 - 2s - loss: 3.9091 - accuracy: 0.3575 - val_loss: 3.9071 - val_accuracy: 0.3520\n",
            "Epoch 4/200\n",
            "60000/60000 - 2s - loss: 3.4872 - accuracy: 0.4229 - val_loss: 2.7781 - val_accuracy: 0.4268\n",
            "Epoch 5/200\n",
            "60000/60000 - 2s - loss: 2.7043 - accuracy: 0.4654 - val_loss: 2.6945 - val_accuracy: 0.4783\n",
            "Epoch 6/200\n",
            "60000/60000 - 2s - loss: 2.6574 - accuracy: 0.4837 - val_loss: 2.6684 - val_accuracy: 0.4850\n",
            "Epoch 7/200\n",
            "60000/60000 - 2s - loss: 2.6312 - accuracy: 0.5059 - val_loss: 2.6597 - val_accuracy: 0.5069\n",
            "Epoch 8/200\n",
            "60000/60000 - 2s - loss: 2.6144 - accuracy: 0.5148 - val_loss: 2.6477 - val_accuracy: 0.5078\n",
            "Epoch 9/200\n",
            "60000/60000 - 2s - loss: 2.6013 - accuracy: 0.5186 - val_loss: 2.6347 - val_accuracy: 0.5246\n",
            "Epoch 10/200\n",
            "60000/60000 - 2s - loss: 2.5891 - accuracy: 0.5242 - val_loss: 2.6336 - val_accuracy: 0.5250\n",
            "Epoch 11/200\n",
            "60000/60000 - 2s - loss: 2.5772 - accuracy: 0.5269 - val_loss: 2.6203 - val_accuracy: 0.5158\n",
            "Epoch 12/200\n",
            "60000/60000 - 2s - loss: 2.5676 - accuracy: 0.5325 - val_loss: 2.6156 - val_accuracy: 0.5291\n",
            "Epoch 13/200\n",
            "60000/60000 - 2s - loss: 2.5578 - accuracy: 0.5368 - val_loss: 2.6053 - val_accuracy: 0.5272\n",
            "Epoch 14/200\n",
            "60000/60000 - 2s - loss: 2.5497 - accuracy: 0.5379 - val_loss: 2.6062 - val_accuracy: 0.5167\n",
            "Epoch 15/200\n",
            "60000/60000 - 2s - loss: 2.5405 - accuracy: 0.5412 - val_loss: 2.5934 - val_accuracy: 0.5354\n",
            "Epoch 16/200\n",
            "60000/60000 - 2s - loss: 2.5305 - accuracy: 0.5460 - val_loss: 2.5926 - val_accuracy: 0.5241\n",
            "Epoch 17/200\n",
            "60000/60000 - 2s - loss: 2.5220 - accuracy: 0.5485 - val_loss: 2.5931 - val_accuracy: 0.5233\n",
            "Epoch 18/200\n",
            "60000/60000 - 2s - loss: 2.5140 - accuracy: 0.5521 - val_loss: 2.5739 - val_accuracy: 0.5477\n",
            "Epoch 19/200\n",
            "60000/60000 - 2s - loss: 2.5085 - accuracy: 0.5506 - val_loss: 2.5747 - val_accuracy: 0.5520\n",
            "Epoch 20/200\n",
            "60000/60000 - 2s - loss: 2.5015 - accuracy: 0.5532 - val_loss: 2.5742 - val_accuracy: 0.5323\n",
            "Epoch 21/200\n",
            "60000/60000 - 2s - loss: 2.4941 - accuracy: 0.5558 - val_loss: 2.5691 - val_accuracy: 0.5503\n",
            "Epoch 22/200\n",
            "60000/60000 - 2s - loss: 2.4888 - accuracy: 0.5555 - val_loss: 2.5684 - val_accuracy: 0.5374\n",
            "Epoch 23/200\n",
            "60000/60000 - 2s - loss: 2.4850 - accuracy: 0.5547 - val_loss: 2.5611 - val_accuracy: 0.5315\n",
            "Epoch 24/200\n",
            "60000/60000 - 2s - loss: 2.4777 - accuracy: 0.5546 - val_loss: 2.5742 - val_accuracy: 0.5351\n",
            "Epoch 25/200\n",
            "60000/60000 - 2s - loss: 2.4729 - accuracy: 0.5567 - val_loss: 2.5711 - val_accuracy: 0.5293\n",
            "Epoch 26/200\n",
            "60000/60000 - 2s - loss: 2.4693 - accuracy: 0.5572 - val_loss: 2.5572 - val_accuracy: 0.5437\n",
            "Epoch 27/200\n",
            "60000/60000 - 2s - loss: 2.4635 - accuracy: 0.5561 - val_loss: 2.5544 - val_accuracy: 0.5427\n",
            "Epoch 28/200\n",
            "60000/60000 - 2s - loss: 2.4588 - accuracy: 0.5576 - val_loss: 2.5487 - val_accuracy: 0.5415\n",
            "Epoch 29/200\n",
            "60000/60000 - 2s - loss: 2.4543 - accuracy: 0.5619 - val_loss: 2.5464 - val_accuracy: 0.5502\n",
            "Epoch 30/200\n",
            "60000/60000 - 2s - loss: 2.4512 - accuracy: 0.5616 - val_loss: 2.5532 - val_accuracy: 0.5517\n",
            "Epoch 31/200\n",
            "60000/60000 - 2s - loss: 2.4490 - accuracy: 0.5633 - val_loss: 2.5521 - val_accuracy: 0.5434\n",
            "Epoch 32/200\n",
            "60000/60000 - 2s - loss: 2.4427 - accuracy: 0.5699 - val_loss: 2.5525 - val_accuracy: 0.5536\n",
            "Epoch 33/200\n",
            "60000/60000 - 2s - loss: 2.4399 - accuracy: 0.5720 - val_loss: 2.5432 - val_accuracy: 0.5638\n",
            "Epoch 34/200\n",
            "60000/60000 - 2s - loss: 2.4372 - accuracy: 0.5760 - val_loss: 2.5414 - val_accuracy: 0.5505\n",
            "Epoch 35/200\n",
            "60000/60000 - 2s - loss: 2.4316 - accuracy: 0.5787 - val_loss: 2.5458 - val_accuracy: 0.5641\n",
            "Epoch 36/200\n",
            "60000/60000 - 2s - loss: 2.4290 - accuracy: 0.5825 - val_loss: 2.5400 - val_accuracy: 0.5653\n",
            "Epoch 37/200\n",
            "60000/60000 - 2s - loss: 2.4255 - accuracy: 0.5839 - val_loss: 2.5431 - val_accuracy: 0.5686\n",
            "Epoch 38/200\n",
            "60000/60000 - 2s - loss: 2.4231 - accuracy: 0.5881 - val_loss: 2.5361 - val_accuracy: 0.5742\n",
            "Epoch 39/200\n",
            "60000/60000 - 2s - loss: 2.4210 - accuracy: 0.5897 - val_loss: 2.5307 - val_accuracy: 0.5739\n",
            "Epoch 40/200\n",
            "60000/60000 - 2s - loss: 2.4171 - accuracy: 0.5945 - val_loss: 2.5333 - val_accuracy: 0.5863\n",
            "Epoch 41/200\n",
            "60000/60000 - 2s - loss: 2.4130 - accuracy: 0.5966 - val_loss: 2.5243 - val_accuracy: 0.5870\n",
            "Epoch 42/200\n",
            "60000/60000 - 2s - loss: 2.4105 - accuracy: 0.6007 - val_loss: 2.5296 - val_accuracy: 0.5861\n",
            "Epoch 43/200\n",
            "60000/60000 - 2s - loss: 2.4067 - accuracy: 0.6016 - val_loss: 2.5290 - val_accuracy: 0.5875\n",
            "Epoch 44/200\n",
            "60000/60000 - 2s - loss: 2.4033 - accuracy: 0.6062 - val_loss: 2.5285 - val_accuracy: 0.5854\n",
            "Epoch 45/200\n",
            "60000/60000 - 2s - loss: 2.4007 - accuracy: 0.6073 - val_loss: 2.5326 - val_accuracy: 0.5849\n",
            "Epoch 46/200\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "60000/60000 - 2s - loss: 2.3975 - accuracy: 0.6087 - val_loss: 2.5297 - val_accuracy: 0.5929\n",
            "Epoch 47/200\n",
            "60000/60000 - 2s - loss: 2.3836 - accuracy: 0.6159 - val_loss: 2.5256 - val_accuracy: 0.5961\n",
            "Epoch 48/200\n",
            "60000/60000 - 2s - loss: 2.3782 - accuracy: 0.6214 - val_loss: 2.5259 - val_accuracy: 0.5975\n",
            "Epoch 49/200\n",
            "60000/60000 - 2s - loss: 2.3761 - accuracy: 0.6223 - val_loss: 2.5268 - val_accuracy: 0.6012\n",
            "Epoch 50/200\n",
            "60000/60000 - 2s - loss: 2.3747 - accuracy: 0.6244 - val_loss: 2.5262 - val_accuracy: 0.6023\n",
            "Epoch 51/200\n",
            "\n",
            "Epoch 00051: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "60000/60000 - 2s - loss: 2.3738 - accuracy: 0.6246 - val_loss: 2.5276 - val_accuracy: 0.6008\n",
            "Epoch 00051: early stopping\n",
            "10000/10000 - 0s - loss: 2.5276 - accuracy: 0.6008\n",
            "model loss after retraining:  [2.52764997177124, 0.6008] \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-c7bc734e5e35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-044715f6f8d8>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mlayer_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'dense_1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Run the Pruning on the layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprune_layer_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# eval and print the results of the pruning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-d4c647c1383f>\u001b[0m in \u001b[0;36mprune_layer_by_name\u001b[0;34m(model, layer_name)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Then prune is and return the pruned model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprune_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-1812885fbdac>\u001b[0m in \u001b[0;36mprune_layer\u001b[0;34m(model, layer)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Run the pruning on the Model and get the Pruned (uncompiled) model as a result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelete_channels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh_apoz_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Recompile the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tfkerassurgeon/operations.py\u001b[0m in \u001b[0;36mdelete_channels\u001b[0;34m(model, layer, channels, node_indexes, copy)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0msurgeon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSurgeon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0msurgeon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'delete_channels'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_indexes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_indexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msurgeon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tfkerassurgeon/surgeon.py\u001b[0m in \u001b[0;36moperate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0moutput_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_inbound_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mnew_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rebuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tfkerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_graph\u001b[0;34m(self, graph_inputs, output_nodes, graph_input_masks)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m# Call the recursive _rebuild_rec method to rebuild the submodel up to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m# each output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_rebuild_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_nodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tfkerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m# Call the recursive _rebuild_rec method to rebuild the submodel up to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m# each output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_rebuild_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_nodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tfkerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_rebuild_rec\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m                     \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutbound_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'Concatenate'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    }
  ]
}
